[
  {
    "objectID": "Home_page.html",
    "href": "Home_page.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to My Website!\n\nWelcome! I’m Yuan Gao, currently a master’s student specializing in Biomedical Informatics & Data Science at Johns Hopkins School of Medicine. My academic journey and passion for technology are dedicated to advancing healthcare through data-driven solutions."
  },
  {
    "objectID": "example-analysis.html",
    "href": "example-analysis.html",
    "title": "Example Data Analysis",
    "section": "",
    "text": "This study aims to analyse NHANES 2003-2004 data to predict the mortality status (binary outcome) for participants 50 years and older."
  },
  {
    "objectID": "example-analysis.html#research-question",
    "href": "example-analysis.html#research-question",
    "title": "Example Data Analysis",
    "section": "",
    "text": "This study aims to analyse NHANES 2003-2004 data to predict the mortality status (binary outcome) for participants 50 years and older."
  },
  {
    "objectID": "example-analysis.html#intended-audience",
    "href": "example-analysis.html#intended-audience",
    "title": "Example Data Analysis",
    "section": "Intended Audience",
    "text": "Intended Audience\nThe intended audience for this study encompasses epidemiologists, public health researchers, geriatric healthcare providers, and health policy makers. Epidemiologists and public health researchers may find the analysis particularly useful for identifying risk factors associated with mortality in older populations, which could inform targeted interventions. Healthcare providers working with older adults can use the findings to refine clinical screening processes and prioritize preventive measures. Lastly, health policy makers can leverage the insights gained to support evidence-based decisions regarding resource allocation for aging populations and to develop policies that address the key determinants of mortality identified in the study."
  },
  {
    "objectID": "example-analysis.html#data-source",
    "href": "example-analysis.html#data-source",
    "title": "Example Data Analysis",
    "section": "Data Source",
    "text": "Data Source\nThe dataset used in this analysis can be found at NHANES 2003-2004 (“NHANES 2003-2004 Data” 2004). The National Health and Nutrition Examination Survey (NHANES) is a cross-sectional, nationally representative survey that assesses demographic, dietary and health-related questions and can be used to better understand differences in health and nutrition across the life-span. Almost all survey data are made publically available by the National Center for Health Statistics (NCHS)."
  },
  {
    "objectID": "example-analysis.html#data-dictionary",
    "href": "example-analysis.html#data-dictionary",
    "title": "Example Data Analysis",
    "section": "Data Dictionary",
    "text": "Data Dictionary\nThe dataset includes the following domains:\n\n\n\n\n\n\n\nVariable\nExplanation\n\n\n\n\nDEMO\nDemographic Variables & Sample Weights\n\n\nDR1TOT\nDietary Interview - Total Nutrient Intakes, First Day\n\n\nDR2TOT\nDietary Interview - Total Nutrient Intakes, Second Day\n\n\nBAX\nBalance\n\n\nBPX\nBlood Pressure\n\n\nBMX\nBody Measures\n\n\nCVX\nCardiovascular Fitness\n\n\nVIX\nVision\n\n\nL13AM\nCholesterol - LDL & Triglycerides\n\n\nL13\nCholesterol - Total & HDL\n\n\nL25\nComplete Blood Count with 5-part Differential - Whole Blood\n\n\nL11PSA\nProstate Specific Antigen (PSA)\n\n\nALQ\nAlcohol Use\n\n\nBPQ\nBlood Pressure & Cholesterol\n\n\nDIQ\nDiabetes\n\n\nHSQ\nCurrent Health Status\n\n\nMCQ\nMedical Conditions\n\n\nSSQ\nSocial Support\n\n\nWHQ\nWeight History\n\n\n\nThe full description of the variables is available at NHANES 2003-2004. For example, DEMO and MCQ components are described at DEMO and MCQ, respectively."
  },
  {
    "objectID": "example-analysis.html#data-wrangling-with-dplyr-and-plotting-using-geom_-functions-from-ggplot2",
    "href": "example-analysis.html#data-wrangling-with-dplyr-and-plotting-using-geom_-functions-from-ggplot2",
    "title": "Example Data Analysis",
    "section": "Data Wrangling with dplyr and plotting using geom_*() functions from ggplot2",
    "text": "Data Wrangling with dplyr and plotting using geom_*() functions from ggplot2\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(factoextra)\nlibrary(FactoMineR)\nlibrary(table1)\nlibrary(gplots)\nlibrary(caret)\nlibrary(RANN)\nlibrary(patchwork)\n\n\nData preprocessing\n\nload(\"/Users/yuangao/Desktop/class/stats quarto/my web/data/nhanes2003-2004.Rda\")\n\n\npredictors_target &lt;- c('RIDAGEYR', 'RIAGENDR', 'BPQ010', 'BPQ060', 'SMQ040', 'DIQ010', 'DIQ050', 'DIQ090', 'MCQ010', 'MCQ053', 'MCQ160A', 'MCQ160B', 'MCQ160K', 'MCQ160L', 'BMXWAIST', 'MCQ160M', 'MCQ220', 'MCQ245A', 'MCQ250A', 'MCQ250B', 'MCQ250C', 'MCQ250E', 'MCQ250F', 'MCQ250G', 'MCQ265', 'SSQ011', 'SSQ051', 'WHQ030', 'WHQ040', 'LBXRDW', 'HSD010', 'BPXPULS', 'BPXML1', 'VIQ200', 'BMXBMI', 'BPXSY1', 'BPXDI1','mortstat')\n\nprint(paste(predictors_target[!predictors_target %in% colnames(nhanes2003_2004)],\"column not in the datset\"))\n\nnhanes &lt;- nhanes2003_2004[,which(colnames(nhanes2003_2004)%in%predictors_target)]\n\nna_target &lt;- nhanes %&gt;% filter(is.na(mortstat))\n\nprint(paste(\"NA in mortstat\",nrow(na_target)))\n\nnhanes &lt;- nhanes %&gt;% filter(!is.na(mortstat))\n\nnhanes$RIDAGEYR &lt;- as.numeric(nhanes$RIDAGEYR)\n\nnhanes &lt;- nhanes %&gt;% dplyr::filter(RIDAGEYR&gt;50)\n\nnhanes$mortstat &lt;- as.factor(nhanes$mortstat)\n\nprint(paste(\"after filter for individuals with age &gt;= 50\",nrow(nhanes),\"left\"))\n\n# What I found if we exclude all the rows with NAs, there will less training variable left and causing a imbalanced dataset. I will just remove BPXSY1,RIDAGEEX and BPXDI1 to keep the power of the model\n\n# Here I imputed the numeric predictors and center\ndummy_vars &lt;- sapply(nhanes, function(x) length(unique(x)) &lt;= 10)\n\nnhanes[, !dummy_vars] &lt;- apply(nhanes[, !dummy_vars], 2, as.numeric)\n\nimputation_method &lt;- \"knnImpute\"\n\npreProcess_missing_data &lt;-  preProcess(nhanes, method = imputation_method)\n\nnhanes_imputed &lt;- predict(preProcess_missing_data,newdata = nhanes)\n\n# Here I will drop the column VIQ 200 because it causes most NAs.\n\nnhanes_imputed &lt;- nhanes_imputed %&gt;% dplyr::select(-VIQ200)\n\nna_counts &lt;- colSums(is.na(nhanes_imputed))\n\n# Print the number of NAs for each column\nprint(na_counts)\n\n# Now drop other rows that contains NAs.\n\nnhanes_imputed &lt;- nhanes_imputed %&gt;% na.omit()\n\nprint(paste(nrow(nhanes_imputed),\"cases left\")) # \"1854 cases left\"\n\n\n\nExploratory Data Analysis\nIn the exploratory data analysis, I used PCA to find PC1 and PC2 loadings for the variables and conducted feature selections to remove the predictors with low PC loading values in PC1 and PC2.\n\n\n\n\n\n\nWhat is PCA?\n\n\n\nPrincipal Component Analysis (PCA) is a statistical procedure that utilizes an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (Maćkiewicz 1993). This is done in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component, in turn, has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set. PCA is sensitive to the relative scaling of the original variables. For more advanced data analysis methods, see (Alpaydin 2020).\n\n\n\n# Visualize data in the PCA dimension\n\nnhanes_imputed &lt;- as.data.frame(apply(nhanes_imputed, 2, as.numeric))\n\nfeatures &lt;- nhanes_imputed %&gt;% dplyr::select(-c(\"mortstat\"))\n\npca_results &lt;- prcomp(features,center = TRUE, scale. = TRUE)\n\npca_df &lt;- data.frame(pca_results$x[, c(1, 2)]) %&gt;% \n  rename(x = PC1, y = PC2) %&gt;% \n  bind_cols(labels = nhanes_imputed$mortstat)\n\n\nggplot(pca_df, aes(x, y, color = as.factor(labels))) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"red\", \"blue\"), labels = c(\"dead\", \"alive\"), name = \"\") +\n  labs(\n    title = \"PCA Visualization of Data\",\n    x = \"PC1\",  \n    y = \"PC2\"\n  )\n\n\n\n\nFrom the plot, we can see the first two dimension of PCA could slightly classfity the mortality of two groups\n\n\nFeature Selection based on PCA\n\npca_var_plot &lt;- fviz_pca_var(pca_results) + ggtitle(\"PCA Variables Plot\")\npca_eig_plot &lt;- fviz_eig(pca_results) + ggtitle(\"PCA Eigenvalues Plot\")\n# Combine the plots\ncombined_plot &lt;- pca_var_plot + pca_eig_plot\n# Plot them side by side\ncombined_plot\n\n\n\n\n\n# Find the variable with high loading scores for the first two PCs\n\nhigh_loading_vars_PC1 &lt;- names(which(abs(pca_results$rotation[, 1]) &gt;= 0.1))\nhigh_loading_vars_PC2 &lt;- names(which(abs(pca_results$rotation[, 2]) &gt;= 0.1))\n\nselected_features &lt;- union(high_loading_vars_PC1,high_loading_vars_PC2)\nnhanes_feature_select &lt;- nhanes_imputed %&gt;% dplyr::select(selected_features,mortstat)\nfeatures &lt;- nhanes_feature_select %&gt;% dplyr::select(-c(\"mortstat\"))\n\npca_results &lt;- prcomp(features,center = TRUE, scale. = TRUE)\npca_df &lt;- data.frame(pca_results$x[, c(1, 2)]) %&gt;% \n  rename(x = PC1, y = PC2) %&gt;% \n  bind_cols(labels = nhanes_imputed$mortstat)\n\n\n\n\n\n\n\nCaution\n\n\n\nFrom the plot, there is no obvious improvement in distinguishing between the two groups using PCA. This may suggest that the data does not have a linear structure that PCA can exploit, or that other methods or parameters should be explored for better group separation.\n\n\n\nggplot(pca_df, aes(x, y, color = as.factor(labels)))+\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"red\", \"blue\"), labels = c(\"dead\",\"alive\"), name = \"\") +\n  labs(\n    title = \"PCA Visualization of Data\",\n    x = \"PC1\",  \n    y = \"PC2\"\n  )\n\n\n\n\n###Model Selection:\nTry logistic regression, support vector machine, random forest and gradient boost using grid search 5-fold cross validation to fine tune and select the best model, report accuracy, sensitivity, specificity and plot bar plot for each algorithm’s best hyper parameters\n\nset.seed(2023)\nlibrary(caret)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(xgboost)\nlibrary(gbm)\n# nhanes_feature_select &lt;- nhanes_imputed %&gt;% dplyr::select(selected_features,mortstat)\nfeatures &lt;- nhanes_feature_select %&gt;% select(-mortstat)\nlabels &lt;- as.factor(nhanes_feature_select$mortstat)\nlevels(labels) &lt;- make.names(levels(labels))\nlabels &lt;- relevel(labels, ref = \"X1\")\n# create a train control cv object.\ncontrol &lt;- trainControl(method = \"cv\",\n                        number = 5, # here I use 5-fold cross-validation\n                        classProbs = TRUE,\n                        summaryFunction = twoClassSummary,\n                        savePredictions = \"all\")\n\n# CV for logistic regression\nlogistic_regression &lt;- train(x = features,\n                             y = factor(labels),\n                             method = \"glm\",\n                             trControl = control,\n                             metric = \"ROC\")\n\n\n# grid CV for penalty regression \npenalty_grid &lt;- expand.grid(\n  alpha = 0:1,\n  lambda = seq(0.0001, 1, length = 100)\n)\n\nlogistic_regression_penalty &lt;- train(x = features,\n                             y = factor(labels),\n                             method = \"glmnet\",\n                             trControl = control,\n                             tuneGrid = penalty_grid,\n                             metric = c(\"ROC\"))\n\n# grid CV for random forest\nrf_grid &lt;- expand.grid(mtry = c(5: length(features)))\n\nrf_model &lt;- train(x = features, \n                  y = factor(labels), \n                  method = \"rf\",\n                  trControl = control,\n                  tuneGrid = rf_grid,\n                  metric = \"ROC\")\n\n# grid CV for svm model\nsvm_grid &lt;- expand.grid(C = c(0.1, 1,5,10),\n                        sigma = c(0.01,0.05, 0.1, 1))\n\nsvm_model &lt;- train(x = features, \n                   y = factor(labels),\n                   tuneGrid = svm_grid,\n                   method = \"svmRadial\",\n                   verbose = FALSE,\n                   trControl = control,\n                   preProcess = c(\"center\", \"scale\"),\n                   metric = \"ROC\")\n\n\n# grid CV for boosting model: gbm\ngbm_grid &lt;- expand.grid(interaction.depth = c(1, 3, 5),\n                          n.trees = c(50, 100, 150),\n                          shrinkage = c(0.01, 0.1, 0.5),\n                          n.minobsinnode = c(5, 10, 20))\n\ngbm_model &lt;- train(x = features, \n                   y = factor(labels),\n                   trControl = control,\n                   tuneGrid = gbm_grid,\n                   method = \"gbm\",\n                   verbose = FALSE,\n                  metric = \"ROC\")\n\n\nbest_lr &lt;- logistic_regression$results %&gt;% dplyr::select(ROC,Sens,Spec)\nbest_penalty_lr &lt;- logistic_regression_penalty$results[rownames(logistic_regression_penalty$bestTune),] %&gt;% dplyr::select(ROC,Sens,Spec)\nbest_rf &lt;- rf_model$results[rownames(rf_model$bestTune),]%&gt;% dplyr::select(ROC,Sens,Spec)\nbest_svm &lt;- svm_model$results[rownames(svm_model$bestTune),]%&gt;% dplyr::select(ROC,Sens,Spec)\nbest_gbm &lt;- gbm_model$result[rownames(gbm_model$bestTune),]%&gt;% dplyr::select(ROC,Sens,Spec)\n\nbest_lr$Model &lt;- \"Logistic Regression\"\nbest_penalty_lr$Model &lt;- \"Penalty Logistic Regression\"\nbest_rf$Model &lt;- \"Random Forest\"\nbest_svm$Model &lt;- \"Support Vector Machine\"\nbest_gbm$Model &lt;- \"Gradient Boost\"\n\nmodels_result &lt;- rbind(best_lr,best_penalty_lr,best_rf,best_svm,best_gbm)\n\nperformance_long &lt;- models_result %&gt;% \n  tidyr::pivot_longer(cols = -Model,\n                      names_to = \"Metric\",\n                      values_to = \"Value\")\n\nggplot(performance_long,aes(x = Metric,y = Value, fill = Model)) +\n  geom_bar(stat = \"identity\",position = \"dodge\", width = 0.9) +\n  geom_text(aes(label = round(Value, 2)), position = position_dodge(width = 0.9), vjust = -0.5)\n\nmodels_result"
  },
  {
    "objectID": "example-analysis.html#results",
    "href": "example-analysis.html#results",
    "title": "Example Data Analysis",
    "section": "results",
    "text": "results\nmodels result plotting (as an image saved locally):\n\n\n\nModel Results\n\n\n\n\n\nROC\nSens\nSpec\nModel\n\n\n\n\n0.7710657\n0.3795556\n0.9033834\nLogistic Regression\n\n\n0.7750547\n0.3753939\n0.9203685\nPenalty Logistic Regression\n\n\n0.7658329\n0.3998384\n0.9029984\nRandom Forest\n\n\n0.7639381\n0.1945859\n0.9446820\nSupport Vector Machine\n\n\n0.7927226\n0.3534949\n0.9469150\nGradient Boost\n\n\n\n\n\nSensitivity (True Positive Rate): \\(\\text{Sensitivity} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\\)\nSpecificity (True Negative Rate): \\(\\text{Specificity} = \\frac{\\text{True Negatives}}{\\text{True Negatives} + \\text{False Positives}}\\)"
  },
  {
    "objectID": "example-analysis.html#discussion",
    "href": "example-analysis.html#discussion",
    "title": "Example Data Analysis",
    "section": "Discussion",
    "text": "Discussion\nBased on the performance plot, the model shows a ROC around 0.75-0.8, sensitivity around 0.4, and specificity around 0.90-0.93. All of the models with the best parameters in the grid search CV have high specificity but low sensitivity. Sensitivity measures the proportion of correctly predicted death cases out of all the cases that were actually dead, while specificity measures the proportion of correctly predicted non-death cases out of all the cases that were actually non-death.\nThis is because the imbalanced nature of the dataset. In our training dataset, only 498 patients are positive cases (dead), while the remaining 1356 cases are negative cases (not dead). This dataset imbalance caused the classifier to learn patterns in the majority class and predict the majority class often, leading to high specificity and low sensitivity\nThe imbalance of the dataset is likely the reason explain the imbalance in the sensitivity and specificity of the model, as the classifier finds it easier to identify patterns in the majority class, resulting in higher specificity and lower sensitivity."
  },
  {
    "objectID": "example-analysis.html#functions-used-in-analysis",
    "href": "example-analysis.html#functions-used-in-analysis",
    "title": "Example Data Analysis",
    "section": "Functions Used in Analysis",
    "text": "Functions Used in Analysis\n\ndplyr Functions Used\n\nfilter(): Subsets rows based on specified conditions. Utilized to:\n\nExclude observations where mortstat is missing.\nSelect individuals older than 50 years.\nRemove rows with any remaining NA values after imputation.\n\nselect(): Drops specific variables from the dataset, such as VIQ200 in this analysis.\nmutate(): Typically used to create or transform variables. The code indicates transformation of variables:\n\nRIDAGEYR was converted to numeric.\nmortstat was converted to a factor.\n\nsummarise(): Used for creating summary statistics.\narrange(): Used for sorting data frames.\n\nThese functions were instrumental in preprocessing the data for subsequent analysis steps.\n\n\nggplot2 Functions Used\nSeveral ggplot2 functions were employed to create visualizations for the analysis:\n\nggplot(): The main function used to initiate the plotting object. It sets up the data and aesthetics (aes) of the plot.\ngeom_point(): Adds scatterplot points to the plots. It was used with a size argument to control the size of the points.\nscale_color_manual(): A scale function used to manually define colors for discrete variables. In the PCA plot, it distinguishes between ‘dead’ and ‘alive’ groups with red and blue colors.\nlabs(): Used to add labels, including the main title, and axis titles to the plots.\ngeom_bar(stat = \"identity\"): Used in the performance plot to create bar charts with heights equal to the data values, which represent model metrics.\ngeom_text(): Used to add text labels to the bars in the performance plot, showing the rounded metric values.\nfviz_pca_var() and fviz_eig(): From the factoextra package, these functions are used to visualize PCA variables and eigenvalues.\n\nThe combination of these functions provides a comprehensive toolkit for data visualization tailored to the requirements of the analysis."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "2018 - 2020\nBEng in Food Science and Engineering\nBeijing Technology and Business University, Beijing, China\n2020 - 2022\nBSc (Hons) in Food Science and Technology\nUniversity College Cork, Cork, Ireland\n2022 - 2024\nMSc in Biomedical Informatics & Data Science\nJohns Hopkins University, Baltimore, USA"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "",
    "text": "2018 - 2020\nBEng in Food Science and Engineering\nBeijing Technology and Business University, Beijing, China\n2020 - 2022\nBSc (Hons) in Food Science and Technology\nUniversity College Cork, Cork, Ireland\n2022 - 2024\nMSc in Biomedical Informatics & Data Science\nJohns Hopkins University, Baltimore, USA"
  }
]