{
  "hash": "f7820a8b0ee628c9858406419c5dbd87",
  "result": {
    "markdown": "---\ntitle: \"Example Data Analysis\"\nbibliography: references.bib\n---\n\n\n## Research Question\nThis study aims to analyse NHANES 2003-2004 data to predict the mortality status (binary outcome) for participants 50 years and older.\n\n\n## Intended Audience\nThe intended audience for this study encompasses epidemiologists, public health researchers, geriatric healthcare providers, and health policy makers. Epidemiologists and public health researchers may find the analysis particularly useful for identifying risk factors associated with mortality in older populations, which could inform targeted interventions. Healthcare providers working with older adults can use the findings to refine clinical screening processes and prioritize preventive measures. Lastly, health policy makers can leverage the insights gained to support evidence-based decisions regarding resource allocation for aging populations and to develop policies that address the key determinants of mortality identified in the study.\n\n\n## Data Source\nThe dataset used in this analysis can be found at [NHANES 2003-2004](https://wwwn.cdc.gov/nchs/nhanes/ContinuousNhanes/Default.aspx?BeginYear=2003) [@nhanes_data_2003_2004]. The National Health and Nutrition Examination Survey (NHANES) is a cross-sectional, nationally representative survey that assesses demographic, dietary and health-related questions and can be used to better understand differences in health and nutrition across the life-span. Almost all survey data are made publically available by the National Center for Health Statistics (NCHS).\n\n\n## Data Dictionary\n\nThe dataset includes the following domains:\n\n| Variable | Explanation                                            |\n|----------|--------------------------------------------------------|\n| DEMO     | Demographic Variables & Sample Weights                 |\n| DR1TOT   | Dietary Interview - Total Nutrient Intakes, First Day  |\n| DR2TOT   | Dietary Interview - Total Nutrient Intakes, Second Day |\n| BAX      | Balance                                                |\n| BPX      | Blood Pressure                                         |\n| BMX      | Body Measures                                          |\n| CVX      | Cardiovascular Fitness                                 |\n| VIX      | Vision                                                 |\n| L13AM    | Cholesterol - LDL & Triglycerides                      |\n| L13      | Cholesterol - Total & HDL                              |\n| L25      | Complete Blood Count with 5-part Differential - Whole Blood |\n| L11PSA   | Prostate Specific Antigen (PSA)                        |\n| ALQ      | Alcohol Use                                            |\n| BPQ      | Blood Pressure & Cholesterol                           |\n| DIQ      | Diabetes                                               |\n| HSQ      | Current Health Status                                  |\n| MCQ      | Medical Conditions                                     |\n| SSQ      | Social Support                                         |\n| WHQ      | Weight History                                         |\n\nThe full description of the variables is available at [NHANES 2003-2004](https://wwwn.cdc.gov/nchs/nhanes/ContinuousNhanes/Default.aspx?BeginYear=2003). For example, DEMO and MCQ components are described at [DEMO](https://wwwn.cdc.gov/Nchs/Nhanes/2003-2004/DEMO_C.htm) and [MCQ](https://wwwn.cdc.gov/Nchs/Nhanes/2003-2004/MCQ_C.htm), respectively.\n\n\n\n## Data Wrangling with `dplyr` and plotting using `geom_*()` functions from `ggplot2`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(factoextra)\nlibrary(FactoMineR)\nlibrary(table1)\nlibrary(gplots)\nlibrary(caret)\nlibrary(RANN)\nlibrary(patchwork)\n```\n:::\n\n\n### Data preprocessing\n\n::: {.cell}\n\n```{.r .cell-code}\nload(\"/Users/yuangao/Desktop/class/stats quarto/my web/data/nhanes2003-2004.Rda\")\n\n\npredictors_target <- c('RIDAGEYR', 'RIAGENDR', 'BPQ010', 'BPQ060', 'SMQ040', 'DIQ010', 'DIQ050', 'DIQ090', 'MCQ010', 'MCQ053', 'MCQ160A', 'MCQ160B', 'MCQ160K', 'MCQ160L', 'BMXWAIST', 'MCQ160M', 'MCQ220', 'MCQ245A', 'MCQ250A', 'MCQ250B', 'MCQ250C', 'MCQ250E', 'MCQ250F', 'MCQ250G', 'MCQ265', 'SSQ011', 'SSQ051', 'WHQ030', 'WHQ040', 'LBXRDW', 'HSD010', 'BPXPULS', 'BPXML1', 'VIQ200', 'BMXBMI', 'BPXSY1', 'BPXDI1','mortstat')\n\nprint(paste(predictors_target[!predictors_target %in% colnames(nhanes2003_2004)],\"column not in the datset\"))\n\nnhanes <- nhanes2003_2004[,which(colnames(nhanes2003_2004)%in%predictors_target)]\n\nna_target <- nhanes %>% filter(is.na(mortstat))\n\nprint(paste(\"NA in mortstat\",nrow(na_target)))\n\nnhanes <- nhanes %>% filter(!is.na(mortstat))\n\nnhanes$RIDAGEYR <- as.numeric(nhanes$RIDAGEYR)\n\nnhanes <- nhanes %>% dplyr::filter(RIDAGEYR>50)\n\nnhanes$mortstat <- as.factor(nhanes$mortstat)\n\nprint(paste(\"after filter for individuals with age >= 50\",nrow(nhanes),\"left\"))\n\n# What I found if we exclude all the rows with NAs, there will less training variable left and causing a imbalanced dataset. I will just remove BPXSY1,RIDAGEEX and BPXDI1 to keep the power of the model\n\n# Here I imputed the numeric predictors and center\ndummy_vars <- sapply(nhanes, function(x) length(unique(x)) <= 10)\n\nnhanes[, !dummy_vars] <- apply(nhanes[, !dummy_vars], 2, as.numeric)\n\nimputation_method <- \"knnImpute\"\n\npreProcess_missing_data <-  preProcess(nhanes, method = imputation_method)\n\nnhanes_imputed <- predict(preProcess_missing_data,newdata = nhanes)\n\n# Here I will drop the column VIQ 200 because it causes most NAs.\n\nnhanes_imputed <- nhanes_imputed %>% dplyr::select(-VIQ200)\n\nna_counts <- colSums(is.na(nhanes_imputed))\n\n# Print the number of NAs for each column\nprint(na_counts)\n\n# Now drop other rows that contains NAs.\n\nnhanes_imputed <- nhanes_imputed %>% na.omit()\n\nprint(paste(nrow(nhanes_imputed),\"cases left\")) # \"1854 cases left\"\n```\n:::\n\n\n### Exploratory Data Analysis\n\nIn the exploratory data analysis, I used PCA to find PC1 and PC2 loadings for the variables and conducted feature selections to remove the predictors with low PC loading values in PC1 and PC2.\n\n::: {.callout-note}\n#### What is PCA?\n\nPrincipal Component Analysis (PCA) is a statistical procedure that utilizes an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components [@MaÄ‡kiewicz_pca]. This is done in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component, in turn, has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set. PCA is sensitive to the relative scaling of the original variables. For more advanced data analysis methods, see [@Alpaydin].\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize data in the PCA dimension\n\nnhanes_imputed <- as.data.frame(apply(nhanes_imputed, 2, as.numeric))\n\nfeatures <- nhanes_imputed %>% dplyr::select(-c(\"mortstat\"))\n\npca_results <- prcomp(features,center = TRUE, scale. = TRUE)\n\npca_df <- data.frame(pca_results$x[, c(1, 2)]) %>% \n  rename(x = PC1, y = PC2) %>% \n  bind_cols(labels = nhanes_imputed$mortstat)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pca_df, aes(x, y, color = as.factor(labels))) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"red\", \"blue\"), labels = c(\"dead\", \"alive\"), name = \"\") +\n  labs(\n    title = \"PCA Visualization of Data\",\n    x = \"PC1\",  \n    y = \"PC2\"\n  )\n```\n\n::: {.cell-output-display}\n![](example-analysis_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nFrom the plot, we can see the first two dimension of PCA could slightly classfity the mortality of two groups\n\n### Feature Selection based on PCA\n\n\n::: {.cell}\n\n```{.r .cell-code}\npca_var_plot <- fviz_pca_var(pca_results) + ggtitle(\"PCA Variables Plot\")\npca_eig_plot <- fviz_eig(pca_results) + ggtitle(\"PCA Eigenvalues Plot\")\n# Combine the plots\ncombined_plot <- pca_var_plot + pca_eig_plot\n# Plot them side by side\ncombined_plot\n```\n\n::: {.cell-output-display}\n![](example-analysis_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find the variable with high loading scores for the first two PCs\n\nhigh_loading_vars_PC1 <- names(which(abs(pca_results$rotation[, 1]) >= 0.1))\nhigh_loading_vars_PC2 <- names(which(abs(pca_results$rotation[, 2]) >= 0.1))\n\nselected_features <- union(high_loading_vars_PC1,high_loading_vars_PC2)\nnhanes_feature_select <- nhanes_imputed %>% dplyr::select(selected_features,mortstat)\nfeatures <- nhanes_feature_select %>% dplyr::select(-c(\"mortstat\"))\n\npca_results <- prcomp(features,center = TRUE, scale. = TRUE)\npca_df <- data.frame(pca_results$x[, c(1, 2)]) %>% \n  rename(x = PC1, y = PC2) %>% \n  bind_cols(labels = nhanes_imputed$mortstat)\n```\n:::\n\n\n::: {.callout-warning}\n#### Caution\n\nFrom the plot, there is no obvious improvement in distinguishing between the two groups using PCA. This may suggest that the data does not have a linear structure that PCA can exploit, or that other methods or parameters should be explored for better group separation.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pca_df, aes(x, y, color = as.factor(labels)))+\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"red\", \"blue\"), labels = c(\"dead\",\"alive\"), name = \"\") +\n  labs(\n    title = \"PCA Visualization of Data\",\n    x = \"PC1\",  \n    y = \"PC2\"\n  )\n```\n\n::: {.cell-output-display}\n![](example-analysis_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n###Model Selection:\n\nTry logistic regression, support vector machine, random forest and gradient boost using grid search 5-fold cross validation to fine tune and select the best model, report accuracy, sensitivity, specificity and plot bar plot for each algorithm's best hyper parameters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2023)\nlibrary(caret)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(xgboost)\nlibrary(gbm)\n# nhanes_feature_select <- nhanes_imputed %>% dplyr::select(selected_features,mortstat)\nfeatures <- nhanes_feature_select %>% select(-mortstat)\nlabels <- as.factor(nhanes_feature_select$mortstat)\nlevels(labels) <- make.names(levels(labels))\nlabels <- relevel(labels, ref = \"X1\")\n# create a train control cv object.\ncontrol <- trainControl(method = \"cv\",\n                        number = 5, # here I use 5-fold cross-validation\n                        classProbs = TRUE,\n                        summaryFunction = twoClassSummary,\n                        savePredictions = \"all\")\n\n# CV for logistic regression\nlogistic_regression <- train(x = features,\n                             y = factor(labels),\n                             method = \"glm\",\n                             trControl = control,\n                             metric = \"ROC\")\n\n\n# grid CV for penalty regression \npenalty_grid <- expand.grid(\n  alpha = 0:1,\n  lambda = seq(0.0001, 1, length = 100)\n)\n\nlogistic_regression_penalty <- train(x = features,\n                             y = factor(labels),\n                             method = \"glmnet\",\n                             trControl = control,\n                             tuneGrid = penalty_grid,\n                             metric = c(\"ROC\"))\n\n# grid CV for random forest\nrf_grid <- expand.grid(mtry = c(5: length(features)))\n\nrf_model <- train(x = features, \n                  y = factor(labels), \n                  method = \"rf\",\n                  trControl = control,\n                  tuneGrid = rf_grid,\n                  metric = \"ROC\")\n\n# grid CV for svm model\nsvm_grid <- expand.grid(C = c(0.1, 1,5,10),\n                        sigma = c(0.01,0.05, 0.1, 1))\n\nsvm_model <- train(x = features, \n                   y = factor(labels),\n                   tuneGrid = svm_grid,\n                   method = \"svmRadial\",\n                   verbose = FALSE,\n                   trControl = control,\n                   preProcess = c(\"center\", \"scale\"),\n                   metric = \"ROC\")\n\n\n# grid CV for boosting model: gbm\ngbm_grid <- expand.grid(interaction.depth = c(1, 3, 5),\n                          n.trees = c(50, 100, 150),\n                          shrinkage = c(0.01, 0.1, 0.5),\n                          n.minobsinnode = c(5, 10, 20))\n\ngbm_model <- train(x = features, \n                   y = factor(labels),\n                   trControl = control,\n                   tuneGrid = gbm_grid,\n                   method = \"gbm\",\n                   verbose = FALSE,\n                  metric = \"ROC\")\n\n\nbest_lr <- logistic_regression$results %>% dplyr::select(ROC,Sens,Spec)\nbest_penalty_lr <- logistic_regression_penalty$results[rownames(logistic_regression_penalty$bestTune),] %>% dplyr::select(ROC,Sens,Spec)\nbest_rf <- rf_model$results[rownames(rf_model$bestTune),]%>% dplyr::select(ROC,Sens,Spec)\nbest_svm <- svm_model$results[rownames(svm_model$bestTune),]%>% dplyr::select(ROC,Sens,Spec)\nbest_gbm <- gbm_model$result[rownames(gbm_model$bestTune),]%>% dplyr::select(ROC,Sens,Spec)\n\nbest_lr$Model <- \"Logistic Regression\"\nbest_penalty_lr$Model <- \"Penalty Logistic Regression\"\nbest_rf$Model <- \"Random Forest\"\nbest_svm$Model <- \"Support Vector Machine\"\nbest_gbm$Model <- \"Gradient Boost\"\n\nmodels_result <- rbind(best_lr,best_penalty_lr,best_rf,best_svm,best_gbm)\n\nperformance_long <- models_result %>% \n  tidyr::pivot_longer(cols = -Model,\n                      names_to = \"Metric\",\n                      values_to = \"Value\")\n\nggplot(performance_long,aes(x = Metric,y = Value, fill = Model)) +\n  geom_bar(stat = \"identity\",position = \"dodge\", width = 0.9) +\n  geom_text(aes(label = round(Value, 2)), position = position_dodge(width = 0.9), vjust = -0.5)\n\nmodels_result\n```\n:::\n\n## results\n\nmodels result plotting (as an image saved locally): \n\n![Model Results](./images/model_results.jpg)\n\n| ROC      | Sens     | Spec     | Model                      |\n|----------|----------|----------|----------------------------|\n| 0.7710657| 0.3795556| 0.9033834| Logistic Regression        |\n| 0.7750547| 0.3753939| 0.9203685| Penalty Logistic Regression|\n| 0.7658329| 0.3998384| 0.9029984| Random Forest              |\n| 0.7639381| 0.1945859| 0.9446820| Support Vector Machine     |\n| 0.7927226| 0.3534949| 0.9469150| Gradient Boost             |\n\n::: {.column-margin}\n\n**Sensitivity** (True Positive Rate): $\\text{Sensitivity} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$\n\n**Specificity** (True Negative Rate): $\\text{Specificity} = \\frac{\\text{True Negatives}}{\\text{True Negatives} + \\text{False Positives}}$\n:::\n\n## Discussion\n\nBased on the performance plot, the model shows a ROC around 0.75-0.8, sensitivity around 0.4, and specificity around 0.90-0.93. All of the models with the best parameters in the grid search CV have high specificity but low sensitivity. Sensitivity measures the proportion of correctly predicted death cases out of all the cases that were actually dead, while specificity measures the proportion of correctly predicted non-death cases out of all the cases that were actually non-death.\n\nThis is because the imbalanced nature of the dataset. In our training dataset, only 498 patients are positive cases (dead), while the remaining 1356 cases are negative cases (not dead). This dataset imbalance caused the classifier to learn patterns in the majority class and predict the majority class often, leading to high specificity and low sensitivity\n\nThe imbalance of the dataset is likely the reason explain the imbalance in the sensitivity and specificity of the model, as the classifier finds it easier to identify patterns in the majority class, resulting in higher specificity and lower sensitivity.\n\n\n## Functions Used in Analysis\n\n### dplyr Functions Used\n- `filter()`: Subsets rows based on specified conditions. Utilized to:\n  - Exclude observations where `mortstat` is missing.\n  - Select individuals older than 50 years.\n  - Remove rows with any remaining NA values after imputation.\n\n- `select()`: Drops specific variables from the dataset, such as `VIQ200` in this analysis.\n\n- `mutate()`: Typically used to create or transform variables. The code indicates transformation of variables:\n  - `RIDAGEYR` was converted to numeric.\n  - `mortstat` was converted to a factor.\n- `summarise()`: Used for creating summary statistics.\n- `arrange()`: Used for sorting data frames.\n\nThese functions were instrumental in preprocessing the data for subsequent analysis steps.\n\n### ggplot2 Functions Used\n\nSeveral `ggplot2` functions were employed to create visualizations for the analysis:\n\n- `ggplot()`: The main function used to initiate the plotting object. It sets up the data and aesthetics (`aes`) of the plot.\n\n- `geom_point()`: Adds scatterplot points to the plots. It was used with a size argument to control the size of the points.\n\n- `scale_color_manual()`: A scale function used to manually define colors for discrete variables. In the PCA plot, it distinguishes between 'dead' and 'alive' groups with red and blue colors.\n\n- `labs()`: Used to add labels, including the main title, and axis titles to the plots.\n\n- `geom_bar(stat = \"identity\")`: Used in the performance plot to create bar charts with heights equal to the data values, which represent model metrics.\n\n- `geom_text()`: Used to add text labels to the bars in the performance plot, showing the rounded metric values.\n\n- `fviz_pca_var()` and `fviz_eig()`: From the `factoextra` package, these functions are used to visualize PCA variables and eigenvalues.\n\nThe combination of these functions provides a comprehensive toolkit for data visualization tailored to the requirements of the analysis.\n\n\n\n",
    "supporting": [
      "example-analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}